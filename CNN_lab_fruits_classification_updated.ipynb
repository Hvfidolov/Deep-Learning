{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "964672a3-f4e2-4bc8-ac2d-875f11900a3e",
   "metadata": {},
   "source": [
    "# CNN fruits classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c989df5a-5f32-4f9c-b5e4-2b7ad35628f9",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815028d8-7604-4053-b395-b3c15e6096f5",
   "metadata": {},
   "source": [
    "https://bitbucket.org/ishaanjav/code-and-deploy-custom-tensorflow-lite-model/raw/a4febbfee178324b2083e322cdead7465d6fdf95/fruits.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f187cf-5bb1-4512-bc3f-4f02fb307aec",
   "metadata": {},
   "source": [
    "### Classification de CNN sur BD Fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "11103c0d-f88e-4596-8e3e-df55740c0ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b6f1b4-b760-4ca2-b38c-9af7f26ce440",
   "metadata": {},
   "source": [
    "### Step 1: Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e712842f-f1d1-43c5-9a15-b66fcec507cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 468 files belonging to 4 classes.\n",
      "Found 468 files belonging to 4 classes.\n",
      "Found 468 files belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "## variables\n",
    "img_height, img_width = 32, 32\n",
    "batch_size = 20\n",
    "\n",
    "## data loading from file in path\n",
    "## batch size (taille du lot sur lequel il s'entraine avant de passer)\n",
    "dataset_train = tf.keras.utils.image_dataset_from_directory(\"fruits/train\", image_size = (img_height, img_width), batch_size = batch_size)\n",
    "dataset_validation = tf.keras.utils.image_dataset_from_directory(\"fruits/train\", image_size = (img_height, img_width), batch_size = batch_size)\n",
    "dataset_test = tf.keras.utils.image_dataset_from_directory(\"fruits/train\", image_size = (img_height, img_width), batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d1436-4748-4a1d-a767-9459cfd40638",
   "metadata": {},
   "source": [
    "### Step 2: Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3cf46f39-f91c-41bf-9c8f-4cd7ea88fa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names=['apple','banana','orange','pineapple']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd46ac40-c2e2-4724-8e65-a6834d1d25cd",
   "metadata": {},
   "source": [
    "### Step 3: Creation du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "df56d4e2-04bd-4dfb-94b5-71deb1be6120",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Rescaling(1./255),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "# Mise à jour de la dernière couche pour inclure les nouvelles classes\n",
    "model.add(tf.keras.layers.Dense(5, activation='softmax'))  # 5 classes au total\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d54b4-095a-4371-a148-7cb8016c2b55",
   "metadata": {},
   "source": [
    "### Step 4: Parametrage du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a164768-2405-440a-bf66-6ba2d84ad2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='SparseCategoricalCrossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e16d7-f8f0-4576-9bd3-c1fc74300358",
   "metadata": {},
   "source": [
    "### Step 5: Entrainement du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "24115703-d7e1-4e9e-b9e8-6bc13cea6d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 92ms/step - accuracy: 0.3466 - loss: 1.2241 - val_accuracy: 0.3269 - val_loss: 1.2308\n",
      "Epoch 2/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.3549 - loss: 1.2349 - val_accuracy: 0.3462 - val_loss: 1.2280\n",
      "Epoch 3/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.3409 - loss: 1.2285 - val_accuracy: 0.3462 - val_loss: 1.2252\n",
      "Epoch 4/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.3278 - loss: 1.2329 - val_accuracy: 0.3462 - val_loss: 1.2226\n",
      "Epoch 5/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.3278 - loss: 1.2350 - val_accuracy: 0.3462 - val_loss: 1.2201\n",
      "Epoch 6/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.3213 - loss: 1.2127 - val_accuracy: 0.3462 - val_loss: 1.2179\n",
      "Epoch 7/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 93ms/step - accuracy: 0.3406 - loss: 1.2243 - val_accuracy: 0.3462 - val_loss: 1.2158\n",
      "Epoch 8/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 98ms/step - accuracy: 0.3497 - loss: 1.2014 - val_accuracy: 0.3462 - val_loss: 1.2138\n",
      "Epoch 9/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.3267 - loss: 1.2254 - val_accuracy: 0.3462 - val_loss: 1.2120\n",
      "Epoch 10/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 114ms/step - accuracy: 0.3368 - loss: 1.2073 - val_accuracy: 0.3462 - val_loss: 1.2103\n",
      "Epoch 11/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.3221 - loss: 1.2258 - val_accuracy: 0.3462 - val_loss: 1.2087\n",
      "Epoch 12/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.3263 - loss: 1.2119 - val_accuracy: 0.3462 - val_loss: 1.2071\n",
      "Epoch 13/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.3258 - loss: 1.2120 - val_accuracy: 0.3462 - val_loss: 1.2056\n",
      "Epoch 14/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 106ms/step - accuracy: 0.3231 - loss: 1.2131 - val_accuracy: 0.3462 - val_loss: 1.2042\n",
      "Epoch 15/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 110ms/step - accuracy: 0.3226 - loss: 1.2337 - val_accuracy: 0.3462 - val_loss: 1.2028\n",
      "Epoch 16/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 112ms/step - accuracy: 0.3037 - loss: 1.1961 - val_accuracy: 0.3462 - val_loss: 1.2015\n",
      "Epoch 17/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.3610 - loss: 1.2181 - val_accuracy: 0.3462 - val_loss: 1.2003\n",
      "Epoch 18/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.3346 - loss: 1.2078 - val_accuracy: 0.3462 - val_loss: 1.1992\n",
      "Epoch 19/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.3565 - loss: 1.1944 - val_accuracy: 0.3462 - val_loss: 1.1981\n",
      "Epoch 20/20\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 103ms/step - accuracy: 0.3264 - loss: 1.2159 - val_accuracy: 0.3462 - val_loss: 1.1971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d95ece5fa0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset_train, validation_data = dataset_validation, epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930b496f-d95e-4d78-9002-3213d55a7b3c",
   "metadata": {},
   "source": [
    "### Step 6: Tester le modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e11d3197-8619-403e-83fe-3d42d56133a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 - 1s - 44ms/step - accuracy: 0.3462 - loss: 1.1971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1970895528793335, 0.3461538553237915]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dataset_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "06a12287-4b15-4caf-a8fd-935ca06a59d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('CNN_lab_fruits_classification_updated.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
